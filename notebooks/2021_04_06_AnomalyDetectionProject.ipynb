{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project Overview** <br>\n",
    "Implement and understand the application of a number of outlier/anomaly detection algorithms\n",
    "\n",
    "**Project Aim** <br>\n",
    "- The purpose of this project is to solve a classification problem in relation to anomaly detection\n",
    "- The objective of the network optimization team is to analyze traces of past activity, which will be used to train an ML system capable of classifying samples of current activity as:\n",
    "    - 0 (normal): current activity corresponds to normal behavior of any working day and. Therefore, no reconfiguration or redistribution of resources is needed.\n",
    "    - 1 (unusual): current activity slightly differs from the behavior usually observed for that time of the day (e.g. due to a strike, demonstration, sports event, etc.), which should trigger a reconfiguration of the base station.\n",
    "    \n",
    "**Project Value**\n",
    "- Target Benefits: Why are we doing this project and where is the value?\n",
    "- Business Needs\n",
    "    - Identifying all of the available benefits (not just ‘enough benefits’ to get the project approved)\n",
    "    - Defining specific measurable end states—the desired business outcomes—that need to be achieved in the business for the benefits to be delivered in full (filling the ‘gap’)\n",
    "    - Maximizing and then quantifying all of the available financial benefits\n",
    "    - Identifying the change activities required to deliver these outcomes, benefits and value.\n",
    "\n",
    "**Data** <br>\n",
    "https://www.kaggle.com/c/anomaly-detection-in-cellular-networks/data\n",
    "https://towardsdatascience.com/adrepository-anomaly-detection-datasets-with-real-anomalies-2ee218f76292\n",
    "\n",
    "During two weeks, different metrics were gathered from a set of 10 base stations, each having a different number of cells, every 15 minutes\n",
    "\n",
    "The dataset is split into training (approx. 80%) and test (approx. 20%) subsets provided as two separate CSV files\n",
    "- The training set: ML-MATT-CompetitionQT1920_train.csv contains 36,904 samples, each having 13 features and a label. Note that there may be erroneous samples and outliers.\n",
    "- The test set: ML-MATT-CompetitionQT1920_test.csv contains 9,158 samples following the same structure as the training set but not including the labels.\n",
    "\n",
    "- Column Definitions\n",
    "    - Time : hour of the day (in the format hh:mm) when the sample was generated.\n",
    "    - CellName1: text string used to uniquely identify the cell that generated the current sample. CellName is in the form xαLTE, where x identifies the base station, and α the cell within that base station (see the example in the right figure).\n",
    "    - PRBUsageUL and PRBUsageDL: level of resource utilization in that cell measured as the portion of Physical Radio Blocks (PRB) that were in use (%) in the previous 15 minutes. Uplink (UL) and downlink (DL) are measured separately.\n",
    "    - meanThrDL and meanThrUL: average carried traffic (in Mbps) during the past 15 minutes. Uplink (UL) and downlink (DL) are measured separately.\n",
    "    - maxThrDL and maxThrUL: maximum carried traffic (in Mbps) measured in the last 15 minutes. Uplink (UL) and downlink (DL) are measured separately.\n",
    "    - meanUEDL and meanUEUL: average number of user equipment (UE) devices that were simultaneously active during the last 15 minutes. Uplink (UL) and downlink (DL) are measured separately.\n",
    "    - maxUEDL and maxUEUL: maximum number of user equipment (UE) devices that were simultaneously active during the last 15 minutes. Uplink (UL) and downlink (DL) are measured separately.\n",
    "    - maxUE_UL+DL: maximum number of user equipment (UE) devices that were active simultaneously in the last 15 minutes, regardless of UL and DL.\n",
    "    - Unusual: labels for supervised learning. A value of 0 determines that the sample corresponds to normal operation, a value of 1 identifies unusual behavior.\n",
    "\n",
    "\n",
    "**Algorithms to Implement** <br>\n",
    "https://machinelearningmastery.com/model-based-outlier-detection-and-removal-in-python/\n",
    "- One-Class Support Vector Machines\n",
    "- Isolation Forests\n",
    "- Local Outlier Factor\n",
    "- Minimum Covariance Determinant (Elliptic Envelope)\n",
    "- DBSCAN\n",
    "\n",
    "**Plot Results and Decision Boundaries and comment on behaviour**\n",
    "\n",
    "\n",
    "**Loss Functions to Consider**\n",
    "- Accuracy\n",
    "- Log-Loss (https://towardsdatascience.com/the-most-awesome-loss-function-172ffc106c99)\n",
    "\n",
    "\n",
    "**Benchmark Perfomance**\n",
    "- Top 10: 0.99244\n",
    "- Top 20: 0.88193\n",
    "- Worst: 0.41447\n",
    "\n",
    "**Resources - Exploratory Data Analysis** <br>\n",
    "~~https://towardsdatascience.com/organize-your-data-and-models-using-the-object-oriented-programming-and-pickle-876a6654494 ~~<br>\n",
    "~~https://www.brighthubpm.com/project-planning/128738-are-your-projects-delivering-business-value/~~ <br>\n",
    "\n",
    "**Resources - Anomaly Detection** <br>\n",
    "Andew Ng - Machine Learning Tutorials (YouTube) <br>\n",
    "~~Multivariate Unsupervised Machine Learning for Anomaly Detection in Enterprise Applications.pdf~~ <br>\n",
    "~~https://machinelearningmastery.com/model-based-outlier-detection-and-removal-in-python/~~ <br>\n",
    "~~https://www.bmc.com/blogs/outlier-and-anomaly-detection/~~ <br>\n",
    "~~https://machinelearningmastery.com/one-class-classification-algorithms/~~ <br>\n",
    "~~https://medium.com/sciforce/anomaly-detection-another-challenge-for-artificial-intelligence-c69d414b14db~~ <br>\n",
    "~~https://medium.com/learningdatascience/anomaly-detection-techniques-in-python-50f650c75aaf~~ <br>\n",
    "~~https://towardsdatascience.com/detecting-weird-data-conformal-anomaly-detection-20afb36c7bcd~~ <br>\n",
    "~~https://machinelearningmastery.com/how-to-use-statistics-to-identify-outliers-in-data/~~ <br>\n",
    "~~https://towardsdatascience.com/detecting-credit-card-fraud-using-machine-learning-a3d83423d3b8~~ <br>\n",
    "~~https://towardsdatascience.com/unsupervised-machine-learning-approaches-for-outlier-detection-in-time-series-using-python-5759c6394e19~~ <br>\n",
    "~~https://medium.com/pinterest-engineering/building-a-real-time-anomaly-detection-system-for-time-series-at-pinterest-a833e6856ddd~~ <br>\n",
    "~~https://towardsdatascience.com/identifying-outliers-with-local-outlier-probabilities-2b5781e86e01#:~:text=By%20comparing%20the%20local%20density,to%20their%20Local%20Outlier%20Probability.~~ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/Users/Rej1992/Documents/AnomalieDetectionMethods_RawData/ML-MATT-CompetitionQT1920_train.csv')\n",
    "test_df = pd.read_csv('/Users/Rej1992/Documents/AnomalieDetectionMethods_RawData/ML-MATT-CompetitionQT1920_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicated_indicies(data):\n",
    "    \n",
    "    ''' This function returns the number of row index for duplicated elements '''\n",
    "    \n",
    "    return data[data.duplicated()].index\n",
    "\n",
    "\n",
    "def determine_class_imbalance(data, col):\n",
    "    \n",
    "    ''' This function determines the class imbalace associated with the target class '''\n",
    "    \n",
    "    return data[col].value_counts()\n",
    "\n",
    "\n",
    "def correct_category_datatype(data, cols):\n",
    "    \n",
    "    ''' This function corrects category type variables'''\n",
    "    \n",
    "    return data[cols].astype('category')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generic Data Overview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns not shared across train/test dataset : {'Unusual'}\n"
     ]
    }
   ],
   "source": [
    "print('Columns not shared across train/test dataset : {}'.format(set(train_df.columns) - set(test_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train/test split for data : 0.25 \n"
     ]
    }
   ],
   "source": [
    "print('The train/test split for data : {} '.format(round(len(test_df)/len(train_df),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataframe dimensions (36904, 14)\n",
      "Training Dataframe dimensions (9158, 13)\n"
     ]
    }
   ],
   "source": [
    "print('Training Dataframe dimensions {}'.format(train_df.shape))\n",
    "print('Training Dataframe dimensions {}'.format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36904 entries, 0 to 36903\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Time         36904 non-null  object \n",
      " 1   CellName     36904 non-null  object \n",
      " 2   PRBUsageUL   36904 non-null  float64\n",
      " 3   PRBUsageDL   36904 non-null  float64\n",
      " 4   meanThr_DL   36904 non-null  float64\n",
      " 5   meanThr_UL   36904 non-null  float64\n",
      " 6   maxThr_DL    36904 non-null  float64\n",
      " 7   maxThr_UL    36904 non-null  float64\n",
      " 8   meanUE_DL    36904 non-null  float64\n",
      " 9   meanUE_UL    36904 non-null  float64\n",
      " 10  maxUE_DL     36815 non-null  float64\n",
      " 11  maxUE_UL     36815 non-null  float64\n",
      " 12  maxUE_UL+DL  36899 non-null  object \n",
      " 13  Unusual      36904 non-null  int64  \n",
      "dtypes: float64(10), int64(1), object(3)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated Rows : 106\n"
     ]
    }
   ],
   "source": [
    "print('Duplicated Rows :', len(duplicated_indicies(train_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    26721\n",
       "1    10183\n",
       "Name: Unusual, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "determine_class_imbalance(train_df, 'Unusual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[['CellName', 'maxUE_UL+DL']] = correct_category_datatype(train_df, ['CellName', 'maxUE_UL+DL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>CellName</th>\n",
       "      <th>PRBUsageUL</th>\n",
       "      <th>PRBUsageDL</th>\n",
       "      <th>meanThr_DL</th>\n",
       "      <th>meanThr_UL</th>\n",
       "      <th>maxThr_DL</th>\n",
       "      <th>maxThr_UL</th>\n",
       "      <th>meanUE_DL</th>\n",
       "      <th>meanUE_UL</th>\n",
       "      <th>maxUE_DL</th>\n",
       "      <th>maxUE_UL</th>\n",
       "      <th>maxUE_UL+DL</th>\n",
       "      <th>Unusual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10:45</td>\n",
       "      <td>3BLTE</td>\n",
       "      <td>11.642</td>\n",
       "      <td>1.393</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.041</td>\n",
       "      <td>15.655</td>\n",
       "      <td>0.644</td>\n",
       "      <td>1.114</td>\n",
       "      <td>1.025</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>09:45</td>\n",
       "      <td>1BLTE</td>\n",
       "      <td>21.791</td>\n",
       "      <td>1.891</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.268</td>\n",
       "      <td>10.273</td>\n",
       "      <td>1.154</td>\n",
       "      <td>1.353</td>\n",
       "      <td>1.085</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07:45</td>\n",
       "      <td>9BLTE</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02:45</td>\n",
       "      <td>4ALTE</td>\n",
       "      <td>1.891</td>\n",
       "      <td>1.095</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.024</td>\n",
       "      <td>60.715</td>\n",
       "      <td>0.825</td>\n",
       "      <td>1.035</td>\n",
       "      <td>0.995</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03:30</td>\n",
       "      <td>10BLTE</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.168</td>\n",
       "      <td>1.011</td>\n",
       "      <td>1.011</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Time CellName  PRBUsageUL  PRBUsageDL  meanThr_DL  meanThr_UL  maxThr_DL  \\\n",
       "0  10:45    3BLTE      11.642       1.393       0.370       0.041     15.655   \n",
       "1  09:45    1BLTE      21.791       1.891       0.537       0.268     10.273   \n",
       "2  07:45    9BLTE       0.498       0.398       0.015       0.010      0.262   \n",
       "3  02:45    4ALTE       1.891       1.095       0.940       0.024     60.715   \n",
       "4  03:30   10BLTE       0.303       0.404       0.016       0.013      0.348   \n",
       "\n",
       "   maxThr_UL  meanUE_DL  meanUE_UL  maxUE_DL  maxUE_UL maxUE_UL+DL  Unusual  \n",
       "0      0.644      1.114      1.025       4.0       3.0           7        1  \n",
       "1      1.154      1.353      1.085       6.0       4.0          10        1  \n",
       "2      0.164      0.995      0.995       1.0       1.0           2        1  \n",
       "3      0.825      1.035      0.995       2.0       2.0           4        1  \n",
       "4      0.168      1.011      1.011       2.0       1.0           3        0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRBUsageUL</th>\n",
       "      <th>PRBUsageDL</th>\n",
       "      <th>meanThr_DL</th>\n",
       "      <th>meanThr_UL</th>\n",
       "      <th>maxThr_DL</th>\n",
       "      <th>maxThr_UL</th>\n",
       "      <th>meanUE_DL</th>\n",
       "      <th>meanUE_UL</th>\n",
       "      <th>maxUE_DL</th>\n",
       "      <th>maxUE_UL</th>\n",
       "      <th>Unusual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36904.000000</td>\n",
       "      <td>36904.000000</td>\n",
       "      <td>36904.000000</td>\n",
       "      <td>36904.000000</td>\n",
       "      <td>36904.000000</td>\n",
       "      <td>36904.000000</td>\n",
       "      <td>36904.000000</td>\n",
       "      <td>36904.000000</td>\n",
       "      <td>36815.000000</td>\n",
       "      <td>36815.000000</td>\n",
       "      <td>36904.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.835090</td>\n",
       "      <td>2.106396</td>\n",
       "      <td>0.560525</td>\n",
       "      <td>0.067610</td>\n",
       "      <td>17.764369</td>\n",
       "      <td>1.791974</td>\n",
       "      <td>1.173441</td>\n",
       "      <td>0.665143</td>\n",
       "      <td>4.190819</td>\n",
       "      <td>3.063371</td>\n",
       "      <td>0.275932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.428206</td>\n",
       "      <td>2.247514</td>\n",
       "      <td>0.727623</td>\n",
       "      <td>0.186555</td>\n",
       "      <td>15.739932</td>\n",
       "      <td>5.028928</td>\n",
       "      <td>0.214065</td>\n",
       "      <td>0.535493</td>\n",
       "      <td>1.772484</td>\n",
       "      <td>1.387446</td>\n",
       "      <td>0.446989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.213000</td>\n",
       "      <td>0.707000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>5.710750</td>\n",
       "      <td>0.362000</td>\n",
       "      <td>1.041000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.547000</td>\n",
       "      <td>1.314000</td>\n",
       "      <td>0.352000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>14.170000</td>\n",
       "      <td>0.703000</td>\n",
       "      <td>1.112000</td>\n",
       "      <td>1.011000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.126000</td>\n",
       "      <td>2.728000</td>\n",
       "      <td>0.718000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>25.059500</td>\n",
       "      <td>1.242000</td>\n",
       "      <td>1.263000</td>\n",
       "      <td>1.051000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>51.333000</td>\n",
       "      <td>77.505000</td>\n",
       "      <td>19.601000</td>\n",
       "      <td>12.461000</td>\n",
       "      <td>140.008000</td>\n",
       "      <td>48.253000</td>\n",
       "      <td>2.915000</td>\n",
       "      <td>2.668000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PRBUsageUL    PRBUsageDL    meanThr_DL    meanThr_UL     maxThr_DL  \\\n",
       "count  36904.000000  36904.000000  36904.000000  36904.000000  36904.000000   \n",
       "mean       7.835090      2.106396      0.560525      0.067610     17.764369   \n",
       "std        8.428206      2.247514      0.727623      0.186555     15.739932   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        1.213000      0.707000      0.140000      0.021000      5.710750   \n",
       "50%        4.547000      1.314000      0.352000      0.040000     14.170000   \n",
       "75%       12.126000      2.728000      0.718000      0.075000     25.059500   \n",
       "max       51.333000     77.505000     19.601000     12.461000    140.008000   \n",
       "\n",
       "          maxThr_UL     meanUE_DL     meanUE_UL      maxUE_DL      maxUE_UL  \\\n",
       "count  36904.000000  36904.000000  36904.000000  36815.000000  36815.000000   \n",
       "mean       1.791974      1.173441      0.665143      4.190819      3.063371   \n",
       "std        5.028928      0.214065      0.535493      1.772484      1.387446   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.362000      1.041000      0.010000      3.000000      2.000000   \n",
       "50%        0.703000      1.112000      1.011000      4.000000      3.000000   \n",
       "75%        1.242000      1.263000      1.051000      5.000000      4.000000   \n",
       "max       48.253000      2.915000      2.668000     12.000000     12.000000   \n",
       "\n",
       "            Unusual  \n",
       "count  36904.000000  \n",
       "mean       0.275932  \n",
       "std        0.446989  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis \n",
    "https://towardsdatascience.com/data-cleaning-with-python-and-pandas-detecting-missing-values-3e9c6ebcf78b <br>\n",
    "https://machinelearningmastery.com/statistical-imputation-for-missing-values-in-machine-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing Value Treatment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_missing_values(train_data):\n",
    "\n",
    "    ''' This function identifies the amount of missing data per variable'''\n",
    "    \n",
    "    print('Nan values =', train_data.isnull().sum().sum())\n",
    "    print(\"\"\"\"\"\")\n",
    "\n",
    "    vars_with_missing = []\n",
    "\n",
    "    for feature in train_data.columns:\n",
    "        missings = train_data[feature].isna().sum()\n",
    "\n",
    "        if missings > 0 :\n",
    "            vars_with_missing.append(feature)\n",
    "            missings_perc = missings / train_data.shape[0]\n",
    "\n",
    "            print('Variable {} has {} records ({:.2%}) with missing values.'.format(feature, missings, missings_perc))\n",
    "    print('In total, there are {} variables with missing values'.format(len(vars_with_missing)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DateTime Treatment**\n",
    "- It looks like the data has been collected at regular time intervals of 15minute periods. Transform this feature to represent this effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12:00    423\n",
       "03:00    417\n",
       "09:45    410\n",
       "07:30    409\n",
       "00:30    407\n",
       "        ... \n",
       "16:30    358\n",
       "20:30    358\n",
       "19:00    357\n",
       "15:45    355\n",
       "21:00    351\n",
       "Name: Time, Length: 96, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Time.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use Statistics to Identify Outliers\n",
    "https://machinelearningmastery.com/how-to-use-statistics-to-identify-outliers-in-data/ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection Algorithm Application\n",
    "**One-Class Support Vector Machines** <br>\n",
    "\n",
    "**Isolation Forest** <br>\n",
    "https://www.bmc.com/blogs/outlier-and-anomaly-detection/\n",
    "\n",
    "**Local Outlier Factor** <br>\n",
    "\n",
    "**Elliptic Envelope** <br>\n",
    "\n",
    "**DBSCAN** <br>\n",
    "\n",
    "**Multivariate anomalie detection** <br>\n",
    "\n",
    "**Conformal Anomaly Detection & Conformal Prediction Framework** <br>\n",
    "https://towardsdatascience.com/detecting-weird-data-conformal-anomaly-detection-20afb36c7bcd\n",
    "\n",
    "**Other Resources** <br>\n",
    "https://machinelearningmastery.com/one-class-classification-algorithms/ <br>\n",
    "https://medium.com/learningdatascience/anomaly-detection-techniques-in-python-50f650c75aaf <br>\n",
    "https://machinelearningmastery.com/model-based-outlier-detection-and-removal-in-python/ <br>\n",
    "https://towardsdatascience.com/identifying-outliers-with-local-outlier-probabilities-2b5781e86e01#:~:text=By%20comparing%20the%20local%20density,to%20their%20Local%20Outlier%20Probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results and Generate Final Results\n",
    "https://towardsdatascience.com/organize-your-data-and-models-using-the-object-oriented-programming-and-pickle-876a6654494"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usecases\n",
    "https://towardsdatascience.com/detecting-credit-card-fraud-using-machine-learning-a3d83423d3b8 <br>\n",
    "https://towardsdatascience.com/unsupervised-machine-learning-approaches-for-outlier-detection-in-time-series-using-python-5759c6394e19 <br>\n",
    "https://medium.com/pinterest-engineering/building-a-real-time-anomaly-detection-system-for-time-series-at-pinterest-a833e6856ddd <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
